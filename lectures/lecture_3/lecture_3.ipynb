{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Технологии искусственного интеллекта\n",
    "\n",
    "© Петров М.В., старший преподаватель кафедры суперкомпьютеров и общей информатики, Самарский университет\n",
    "\n",
    "## Лекция 3. Задачи классификации. Метрики качества\n",
    "\n",
    "### Содержание\n",
    "\n",
    "1. [Введение](#3.1-Введение)\n",
    "2. [Метод $k$-ближайших соседей](#3.2-Метод-k-ближайших-соседей)\n",
    "3. [Датасет `Rain in Australia` для бинарной классификации](#3.3-Датасет-Rain-in-Australia-для-бинарной-классификации)\n",
    "4. [Подготовка данных](#3.4-Подготовка-данных)\n",
    "5. [Перекодирование признака](#3.5-Перекодирование-признака)\n",
    "6. [Подготовка данных (продолжение)](#3.6-Подготовка-данных-(продолжение))\n",
    "7. [Обучение и предсказание](#3.7-Обучение-и-предсказание)\n",
    "8. [Оценка качества модели](#3.8-Оценка-качества-модели)\n",
    "9. [Метрики оценки точности бинарной классификации](#3.9-Метрики-оценки-точности-бинарной-классификации)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.1 Введение\n",
    "\n",
    "Гайды:\n",
    "- [Открытый курс машинного обучения. Тема 3. Классификация, деревья решений и метод ближайших соседей](https://habr.com/ru/companies/ods/articles/322534/)\n",
    "\n",
    "Классическое, общее определение машинного обучения звучит так (T. Mitchell \"Machine learning\", 1997):\n",
    "> Говорят, что компьютерная программа обучается при решении какой-то задачи из класса $T$, если ее производительность, согласно метрике $P$, улучшается при накоплении опыта $E$.\n",
    "\n",
    "Среди самых популярных задач $T$ в машинном обучении:\n",
    "- Классификация – отнесение объекта к одной из категорий на основании его признаков.\n",
    "- Регрессия – прогнозирование количественного признака объекта на основании прочих его признаков.\n",
    "- Кластеризация – разбиение множества объектов на группы на основании признаков этих объектов так, чтобы внутри групп объекты были похожи между собой, а вне одной группы – менее похожи.\n",
    "- Нахождение аномалий – поиск объектов, \"сильно непохожих\" на все остальные в выборке, либо на какую-то группу объектов.\n",
    "- Другие задачи, более специфичные. Хороший обзор дан в главе \"Machine Learning basics\" книги [\"Deep Learning\": Ian Goodfellow, Yoshua Bengio, Aaron Courville, 2016](http://www.deeplearningbook.org/).\n",
    "\n",
    "Под опытом $E$ понимаются данные, и в зависимости от данных алгоритмы машинного обучения разделяются на 2 вида:\n",
    "- обучение с учителем - `supervised learning`;\n",
    "- обучение без учителя - `unsupervised learning`.\n",
    "\n",
    "В задачах обучения без учителя имеется выборка, состоящая из объектов, описываемых набором признаков. В задачах обучения с учителем вдобавок к этому для каждого объекта некоторой выборки, называемой обучающей, известен целевой признак – по сути это то, что хотелось бы прогнозировать для прочих объектов, не из обучающей выборки.\n",
    "\n",
    "#### Пример\n",
    "\n",
    "Задачи классификации и регрессии – это задачи обучения с учителем. В качестве примера будем представлять задачу кредитного скоринга: на основе накопленных кредитной организацией данных о своих клиентах хочется прогнозировать невозврат кредита. Здесь для алгоритма опыт $E$ – это имеющаяся обучающая выборка: набор объектов (людей), каждый из которых характеризуется набором признаков (таких как возраст, зарплата, тип кредита, невозвраты в прошлом и т.д.), а также целевым признаком. Если этот целевой признак – просто факт невозврата кредита (1 или 0, т.е. банк знает о своих клиентах, кто вернул кредит, а кто – нет), то это задача (бинарной) классификации. Если известно, на сколько по времени клиент затянул с возвратом кредита, и хочется то же самое прогнозировать для новых клиентов, то это будет задачей регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.2 Метод $k$-ближайших соседей\n",
    "\n",
    "Метод $k$-ближайших соседей (`k-nearest neighbors algorithm`, `k-NN`) — метрический алгоритм для автоматической классификации объектов или регрессии.\n",
    "В случае использования метода для классификации объект присваивается тому классу, который является наиболее распространённым среди $k$ соседей данного элемента, классы которых уже известны.\n",
    "Алгоритм может быть применим к выборкам с большим количеством атрибутов (многомерным). Для этого перед применением нужно определить функцию расстояния; классический вариант такой функции - евклидова метрика.\n",
    "\n",
    "Разные атрибуты могут иметь разный диапазон представленных значений в выборке (например атрибут $А$ представлен в диапазоне от $0.1$ до $0.5$, а атрибут $Б$ представлен в диапазоне от $1000$ до $5000$), то значения дистанции могут сильно зависеть от атрибутов с бо́льшими диапазонами. Поэтому данные обычно подлежат `нормализации`.\n",
    "\n",
    "#### Датасет - Ирисы Фишера\n",
    "\n",
    "[Ирисы Фишера](https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0) состоят из данных о 150 экземплярах ириса, по 50 экземпляров из трёх видов — `Ирис щетинистый` (`Iris setosa`), `Ирис виргинский` (`Iris virginica`) и `Ирис разноцветный` (`Iris versicolor`).\n",
    "Для каждого экземпляра измерялись четыре характеристики (в сантиметрах):\n",
    "- Длина наружной доли околоцветника (англ. `sepal length`);\n",
    "- Ширина наружной доли околоцветника (англ. `sepal width`);\n",
    "- Длина внутренней доли околоцветника (англ. `petal length`);\n",
    "- Ширина внутренней доли околоцветника (англ. `petal width`).\n",
    "\n",
    "На основании этого набора данных требуется построить правило классификации, определяющее вид растения по данным измерений. Это задача многоклассовой классификации, так как имеется три класса - три вида ириса.\n",
    "Один из классов (`Iris setosa`) линейно-разделим от двух остальных.  \n",
    "\n",
    "> Для работы нам понадобится библиотека [`scikit-learn`](https://scikit-learn.org/stable/). [Установка](https://scikit-learn.org/stable/install.html):\n",
    "> ```bash\n",
    "> pip install -U scikit-learn\n",
    "> ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "dataset = datasets.load_iris()\n",
    "print(list(dataset.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Значение ключа DESCR – это краткое описание набора данных\n",
    "print(dataset['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Значение ключа target_names – массив меток классов (в данном случае сорта цветов)\n",
    "list(dataset['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Список названий полей-признаков\n",
    "list(dataset['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Сами признаки записаны в numpy-массиве data\n",
    "type(dataset['data']), dataset['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Первые пять строк массива data\n",
    "dataset['data'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# \"Ответы\" записаны в target\n",
    "type(dataset['target']), dataset['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(dataset['target'])\n",
    "# Значения чисел задаются массивом target_names: 0 – setosa, 1 – versicolor, а 2 – virginica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Разделение выборки на обучающую и тестовую\n",
    "\n",
    "Разобьём весь датасет на две части. Одна часть данных используется для построения модели машинного обучения и называется *обучающими данными* (*training data*) или *обучающим набором* (*training set*). Остальные данные будут использованы для оценки качества модели, их называют *тестовыми данными* (*test data*), *тестовым набором* (*test set*) или *контрольным набором* (*hold-out set*).\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"images/l3_1.svg\" width=\"500\" title=\"Обучение и тестирование модели\"/>\n",
    "  <p style=\"text-align: center\">\n",
    "    Рисунок 1 - Обучение и тестирование модели\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "Обычно отбирают в обучающий набор $70\\text{-}80\\%$ строк данных, и оставшиеся $\\%$ объявляются тестовым набором.\n",
    "В библиотеке `scikit-learn` есть функция `train_test_split`, которая перемешивает набор данных и разбивает его на две части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "ex_X, ex_y = dataset.data, dataset.target\n",
    "ex_X = ex_X[:, :2]\n",
    "\n",
    "ex_X_train, ex_X_test, ex_y_train, ex_y_test = train_test_split(\n",
    "    ex_X, ex_y, stratify=ex_y, train_size=0.75, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"X_train shape: {ex_X_train.shape}\")\n",
    "print(f\"y_train shape: {ex_y_train.shape}\")\n",
    "print(f\"X_test shape: {ex_X_test.shape}\")\n",
    "print(f\"y_test shape: {ex_y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Создание объекта алгоритма/модели-предсказателя\n",
    "\n",
    "В `sklearn` все модели машинного обучения реализованы в собственных классах, называемых классами `Estimator`. Алгоритм классификации на основе метода $k$ ближайших соседей реализован в классификаторе [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) модуля `sklearn.neighbors`. Прежде чем использовать эту модель, нам нужно создать объект-экземпляр класса, указав параметры модели. Самым важным параметром `KNeighborsClassifier` является количество соседей, которые мы установим равным $3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "ex_model_knn = KNeighborsClassifier(n_neighbors=3, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "ex_model_knn.fit(ex_X_train, ex_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# magic function - см. Interactive Plotting\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "from ipywidgets import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, colormaps\n",
    "# см. https://ipython.readthedocs.io/en/stable/interactive/plotting.html\n",
    "# Starting with IPython 5.0 and matplotlib 2.0 you can avoid the use of IPython’s specific magic\n",
    "# and use matplotlib.pyplot.ion()/matplotlib.pyplot.ioff() which have the advantages of working outside of IPython as well.\n",
    "# plt.ion()\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import DistanceMetric\n",
    "\n",
    "# Тестовая точка - sepal length, width\n",
    "test_point = [7, 3.5]\n",
    "tpp = ex_model_knn.predict([test_point])\n",
    "\n",
    "# Ближайшие 6 соседей\n",
    "n_d, n_i = ex_model_knn.kneighbors([test_point], n_neighbors=6, return_distance=True)\n",
    "points = np.reshape(ex_X_train[n_i].ravel(), (-1, 2))\n",
    "color_l = np.array([[0, 126, 89], [219, 96, 0], [105, 45, 171]]) / 255.0\n",
    "cmap_custom = colors.ListedColormap(color_l)\n",
    "\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 5))\n",
    "ax[0].set_aspect('equal')\n",
    "ax[1].set_aspect('equal')\n",
    "sc = ax[0].scatter(ex_X_train[:, 0], ex_X_train[:, 1], c=ex_y_train, cmap=cmap_custom)\n",
    "# ax[0].set_facecolor((0.7, 0.7, 0.7))\n",
    "ax[0].legend(*sc.legend_elements())\n",
    "ax[0].set_xlabel(dataset.feature_names[0])\n",
    "ax[0].set_ylabel(dataset.feature_names[1])\n",
    "scc = sc.get_cmap()\n",
    "\n",
    "ax[0].plot(test_point[0], test_point[1], 'ro')\n",
    "circle = plt.Circle((test_point), np.max(n_d), color='r', ls='--', fill=False)\n",
    "ax[0].add_patch(circle)\n",
    "for i in range(6):\n",
    "    p = points[i, :]\n",
    "    p = np.vstack((p, test_point))\n",
    "    ax[0].plot(p[:, 0], p[:, 1], 'r--')\n",
    "\n",
    "DecisionBoundaryDisplay.from_estimator(\n",
    "        ex_model_knn,\n",
    "        ex_X,\n",
    "        alpha=0.25,\n",
    "        ax=ax[1],\n",
    "        response_method=\"predict\",\n",
    "        plot_method=\"pcolormesh\",\n",
    "        cmap=cmap_custom,\n",
    "        xlabel=dataset.feature_names[0],\n",
    "        ylabel=dataset.feature_names[1],\n",
    "        shading=\"auto\",\n",
    "    )\n",
    "circle = plt.Circle((test_point), np.max(n_d), color=scc(tpp/2), ls='--', fill=False)\n",
    "ax[1].add_patch(circle)\n",
    "ax[1].scatter(ex_X_train[:, 0], ex_X_train[:, 1], c=ex_y_train, cmap=cmap_custom)\n",
    "ax[1].legend(*sc.legend_elements())\n",
    "for i in range(6):\n",
    "    p = points[i, :]\n",
    "    p = np.vstack((p, test_point))\n",
    "    ax[1].plot(p[:, 0], p[:, 1], ls = '--', color = 'r')\n",
    "ax[1].plot(test_point[0], test_point[1], marker='o', color = scc(tpp/2))\n",
    "ax[0].set_xlim(ax[1].get_xlim())\n",
    "ax[0].set_ylim(ax[1].get_ylim())\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.3 Датасет [Rain in Australia](https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package) для бинарной классификации\n",
    "\n",
    "#### Описание датасета\n",
    "\n",
    "Датасет содержит данные о метеонаблюдениях в Австралии, цель - прогнозирование дождя на следующий день. Целевой признак - `RainTomorrow`.\n",
    "\n",
    "| Признак       | Описание                                                                                               | Единицы измерения   |\n",
    "|---------------|--------------------------------------------------------------------------------------------------------|---------------------|\n",
    "| Location      | The common name of the location of the weather station                                                 |\n",
    "| MinTemp       | Minimum temperature in the 24 hours to 9am. Sometimes only known to the nearest whole degree.          | degrees Celsius\n",
    "| MaxTemp       | Maximum temperature in the 24 hours from 9am. Sometimes only known to the nearest whole degree.        | degrees Celsius\n",
    "| Rainfall      | Precipitation (rainfall) in the 24 hours to 9am. Sometimes only known to the nearest whole millimetre. | millimetres\n",
    "| Sunshine      | Bright sunshine in the 24 hours to midnight                                                            | hours\n",
    "| WindGustDir   | Direction of strongest gust in the 24 hours to midnight                                                | 16 compass points\n",
    "| WindGustSpeed | Speed of strongest wind gust in the 24 hours to midnight                                               | kilometres per hour\n",
    "| WindDir9am    | Wind direction averaged over 10 minutes prior to 9 am                                                  | compass points\n",
    "| WindDir3pm    | Wind direction averaged over 10 minutes prior to 3 pm                                                  | compass points\n",
    "| WindSpeed9am  | Wind speed averaged over 10 minutes prior to 9 am                                                      | kilometres per hour\n",
    "| WindSpeed3pm  | Wind speed averaged over 10 minutes prior to 3 pm                                                      | kilometres per hour\n",
    "| Humidity9am   | Relative humidity at 9 am                                                                              | percent\n",
    "| Humidity3pm   | Relative humidity at 3 pm                                                                              | percent\n",
    "| Pressure9am   | Atmospheric pressure reduced to mean sea level at 9 am                                                 | hectopascals\n",
    "| Pressure3pm   | Atmospheric pressure reduced to mean sea level at 3 pm                                                 | hectopascals\n",
    "| Cloud9am      | Fraction of sky obscured by cloud at 9 am                                                              | eighths\n",
    "| Cloud3pm      | Fraction of sky obscured by cloud at 3 pm                                                              | eighths\n",
    "| Temp9am       | Temperature at 9 am                                                                                    | degrees Celsius\n",
    "| Temp3pm       | Temperature at 3 pm                                                                                    | degrees Celsius\n",
    "| RainToday     | The rain for that day was 1mm or more                                                                  | Yes or No\n",
    "| RainTomorrow  | The rain for that day was 1mm or more. The target variable to predict.                                 | Yes or No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# magic function - см. Interactive Plotting\n",
    "%matplotlib inline\n",
    "%matplotlib widget\n",
    "from ipywidgets import *\n",
    "import matplotlib.pyplot as plt\n",
    "# см. https://ipython.readthedocs.io/en/stable/interactive/plotting.html\n",
    "# Starting with IPython 5.0 and matplotlib 2.0 you can avoid the use of IPython’s specific magic\n",
    "# and use matplotlib.pyplot.ion()/matplotlib.pyplot.ioff() which have the advantages of working outside of IPython as well.\n",
    "# plt.ion()\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "# путь к папке с данными\n",
    "data_path = \"../lecture_3/data\"\n",
    "# датасет: Rain in Australia: https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package\n",
    "df = pd.read_csv(Path(data_path, 'weatherAUS.csv'))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.4 Подготовка данных\n",
    "#### Проверка целевого признака `RainTomorrow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df['RainTomorrow'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Дропнем строки с null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(df[df['RainTomorrow'].isna()].index)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df['RainTomorrow'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df['RainTomorrow'].value_counts() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Проверка категориальных признаков\n",
    "##### Заполним отсутствующие значения\n",
    "\n",
    "> [pandas.DataFrame.mode](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html) - возвращает список наиболее часто встречающихся значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Сформируем массив категориальных признаков `cat_cols`\n",
    "cat_cols = [var for var in df.columns if df[var].dtype == 'object']\n",
    "df[cat_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Выведем количество пропущенных данных в каждом из категориальных признаков\n",
    "cat_null = df[cat_cols].isnull().sum()\n",
    "cat_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[cat_null[cat_null > 0].index].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пояснение для следующей ячейки\n",
    "df[cat_cols[1]].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cat_cols[1]].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "df[cat_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Мощность признаков (cardinality)\n",
    "Мощность признака &ndash; количество уникальных значений признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "len_max = max([len(col) for col in cat_cols])\n",
    "for col in cat_cols:\n",
    "    print(f\"{col:<{len_max}} labels: {len(df[col].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Признак `Date` имеет высокую мощность, что может усложнить задачу классификации. Разобьем дату на составные части."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df.drop('Date', axis=1, inplace = True)\n",
    "cat_cols.remove('Date')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Признак `Location`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"\\\"Location\\\" label count: {len(df.Location.unique())}\")\n",
    "print(df.Location.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.5 Перекодирование признака\n",
    "> Кодирование категориальных признаков - преобразование категориальных признаков в численное представление по некоторым правилам.\n",
    "\n",
    "Гайды:\n",
    "- [sklearn: Encoding categorical features](https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-categorical-features)\n",
    "- [sklearn: LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder)\n",
    "- [sklearn: OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "- [pandas: factorize](https://pandas.pydata.org/docs/reference/api/pandas.factorize.html)\n",
    "- [Хабр: Отличия LabelEncoder и OneHotEncoder в SciKit Learn](https://habr.com/ru/articles/456294/)\n",
    "- [Хабр: Категориальные признаки](https://habr.com/ru/articles/666234/)\n",
    "\n",
    "Рассмотрим 2 подхода.\n",
    "\n",
    "- `Label Encoder`  \n",
    "  Преобразование представляет собой однозначное соответствие `уникальное значение категориального признака` &harr; `число`, диапазон $[0, N-1]$.\n",
    "  > Главный недостаток `Label Encoder`'a - создание избыточных зависимостей в данных (порядок и количественное отношение). Используется, как правило, для кодирования целевой переменной.\n",
    "  >\n",
    "  > Encode target labels with value between 0 and n_classes-1.\n",
    "  > This transformer should be used to encode *target values*, i.e. y, and not the input X.\n",
    "\n",
    "  Перекодируем наш признак `Location` (только в качестве примера):\n",
    "  $$\n",
    "  \\begin{bmatrix}\n",
    "      \\text{Adelaide} \\\\[0.3em]\n",
    "      \\text{Albany}   \\\\[0.3em]\n",
    "      \\text{Albury}   \\\\[0.3em]\n",
    "      \\cdots           \\\\[0.3em]\n",
    "      \\text{Woomera}  \\\\[0.3em]\n",
    "  \\end{bmatrix}_{\\; 49 \\times 1} \\quad \\rightarrow{} \\quad\n",
    "  \\begin{bmatrix}\n",
    "      0 \\\\[0.3em]\n",
    "      1 \\\\[0.3em]\n",
    "      2 \\\\[0.3em]\n",
    "      \\vdots \\\\[0.3em]\n",
    "      48 \\\\[0.3em]\n",
    "  \\end{bmatrix}_{\\; 49 \\times 1}\n",
    "  $$\n",
    "- `One-Hot Encoder`  \n",
    "  Каждому уникальному значению признака ставится в соответсвие бинарный вектор, состоящий из нулей и одной единицы. Каждое значение такого вектора означает принадлежность значения признака одному из уникальных значений:\n",
    "  $$\n",
    "  \\begin{matrix}\n",
    "  & \\\\\n",
    "  \\begin{bmatrix} A \\\\ B \\\\ C \\\\ D \\end{bmatrix} \\quad \\rightarrow{} \\quad\n",
    "    \\left [ \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right .\n",
    "  \\end{matrix}\n",
    "  \\hspace{-1.2em}\n",
    "  \\begin{matrix}\n",
    "      A & B & C & D \\\\\n",
    "      1 & 0 & 0 & 0 \\\\\n",
    "      0 & 1 & 0 & 0 \\\\\n",
    "      0 & 0 & 1 & 0 \\\\\n",
    "      0 & 0 & 0 & 1\n",
    "  \\end{matrix}\n",
    "  \\hspace{-0.2em}\n",
    "  \\begin{matrix}\n",
    "  & \\\\\n",
    "  \\left . \\vphantom{ \\begin{matrix} 12 \\\\ 12 \\\\ 12 \\\\ 12 \\end{matrix} } \\right ]\n",
    "      \\begin{matrix} A \\\\ B \\\\ C \\\\ D \\end{matrix}\n",
    "  \\end{matrix}\n",
    "  $$\n",
    "  > Главный недостаток `One-Hot Encoder`'a - избыточное количество данных, вместо одного признака с $N$ уникальными значениями мы получаем $N$ бинарных признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Перекодирование признака `LabelEncoder`'ом с использованием `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Пример кодирования LabelEncoder'ом с использованием sklearn\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "cat_arr = ['Albury', 'BadgerysCreek', 'Cobar', 'CoffsHarbour', 'Moree']\n",
    "enc.fit(cat_arr)\n",
    "print(f\"Encoded classes: {enc.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "enc.transform(['BadgerysCreek', 'CoffsHarbour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "enc.inverse_transform([0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Перекодирование признака `LabelEncoder`'ом с использованием `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Пример кодирования LabelEncoder'ом с использованием pandas\n",
    "pd.factorize(cat_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "codes, uniques = pd.factorize(['Albury', 'BadgerysCreek', 'Cobar', 'CoffsHarbour', 'Moree', 'Albury', 'Cobar', 'Cobar'])\n",
    "print(codes, uniques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Перекодирование признака `OneHotEncoder`'ом с использованием `sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Пример кодирования OneHotEncoder'ом с использованием sklearn\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(np.reshape([cat_arr], (-1, 1)))\n",
    "print(f\"Encoded classes: {enc.categories_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data_new = enc.transform([['BadgerysCreek'], ['CoffsHarbour']])\n",
    "data_new.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "enc.inverse_transform([[0., 0., 1., 0., 0.],\n",
    "                       [0., 0., 0., 0., 1.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Перекодирование признака `OneHotEncoder`'ом с использованием `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Пример кодирования OneHotEncoder'ом с использованием pandas\n",
    "cat_dummy = pd.get_dummies(cat_arr)\n",
    "cat_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.from_dummies(cat_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "pd.get_dummies(df.Location).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.6 Подготовка данных (продолжение)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Подготовка количественных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Сформируем массив количественных признаков `num_cols`\n",
    "num_cols = [var for var in df.columns if not df[var].dtype == 'object']\n",
    "df[num_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[num_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(round(df[num_cols].describe(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.title('Correlation Heatmap of Rain in Australia Dataset')\n",
    "cmap = sns.diverging_palette(240, 0, s=70, l=80, as_cmap=True)\n",
    "ax_sns = sns.heatmap(ax = ax, data=df[num_cols].corr(), cmap=cmap, square=True, annot=True, fmt='.2f', linecolor='white')\n",
    "ax_sns.set_xticklabels(ax_sns.get_xticklabels(), rotation=45)\n",
    "ax_sns.set_yticklabels(ax_sns.get_yticklabels(), rotation=0)\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Заполним отсутствующие значения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_cols = [var for var in df.columns if not df[var].dtype == 'object']\n",
    "df[num_cols].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "for col in num_cols:\n",
    "    df.fillna({col: df[col].median()}, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Кодирование категориальных признаков\n",
    "##### Признак `Location`\n",
    "Перекодируем наш признак с использованием `One-Hot Encoder`.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    \\text{Adelaide} \\\\[0.3em]\n",
    "    \\text{Albany}   \\\\[0.3em]\n",
    "    \\text{Albury}   \\\\[0.3em]\n",
    "    \\cdots          \\\\[0.3em]\n",
    "    \\text{Woomera}  \\\\[0.3em]\n",
    "\\end{bmatrix}_{\\; 49 \\times 1} \\quad \\rightarrow{} \\quad\n",
    "\\begin{bmatrix}\n",
    "    1 & 0 & 0 & \\cdots & 0 \\\\[0.3em]\n",
    "    0 & 1 & 0 & \\cdots & 0 \\\\[0.3em]\n",
    "    0 & 0 & 1 & \\cdots & 0 \\\\[0.3em]\n",
    "    \\vdots & \\vdots & \\vdots & \\ddots & 0 \\\\[0.3em]\n",
    "    0 & 0 & 0 & \\cdots & 1 \\\\[0.3em]\n",
    "\\end{bmatrix}_{\\; 49 \\times 49}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_loc_dummy = pd.get_dummies(df.Location, prefix='Location')\n",
    "df_loc_dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop('Location', axis = 1)\n",
    "df = df.join(df_loc_dummy)\n",
    "df.info(max_cols=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cat_left = [var for var in df.columns if df[var].dtype == 'object']\n",
    "cat_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Закодируем категориальные признаки направления ветра `OneHotEncoder`'ом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "cat_left = ['WindGustDir', 'WindDir9am', 'WindDir3pm']\n",
    "df = pd.get_dummies(data=df, columns=cat_left, drop_first=False)\n",
    "df.info(max_cols=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Преобразуем бинарные признаки `RainToday` и `RainTomorrow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df['RainToday'].replace({'No': 0, 'Yes': 1}, inplace = True)\n",
    "df['RainTomorrow'].replace({'No': 0, 'Yes': 1}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.replace({'RainToday': {'No': 0, 'Yes': 1}}, inplace = True)\n",
    "df.replace({'RainTomorrow': {'No': 0, 'Yes': 1}}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Outliers (выбросы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "num_cols_ext = copy.deepcopy(num_cols)\n",
    "num_cols_ext.append('RainToday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 7.5))\n",
    "sns.boxplot(data = df[num_cols_ext], ax = ax)\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Нормализация признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[num_cols_ext].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "all_cols = list(df.columns)\n",
    "mm_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "features_scaled = mm_scaler.fit_transform(df[all_cols])\n",
    "df_scaled = pd.DataFrame(features_scaled, columns=all_cols)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_scaled.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Ouliers scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 7.5))\n",
    "sns.boxenplot(data = df_scaled[num_cols_ext], ax = ax)\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Подправим outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_scaled.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Определим границы ящика с усами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_bounds(dataframe, col):\n",
    "    iqr = dataframe[col].quantile(0.75) - dataframe[col].quantile(0.25)\n",
    "    lower_bound = dataframe[col].quantile(0.25) - 1.5 * iqr\n",
    "    upper_bound = dataframe[col].quantile(0.75) + 1.5 * iqr\n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "num_cols_clean = ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm']\n",
    "\n",
    "bounds_dict = dict()\n",
    "\n",
    "for col in num_cols_clean:\n",
    "    lb, ub = get_bounds(df_scaled, col)\n",
    "    bounds_dict[col] = [lb, ub]\n",
    "    print(f\"{col:<13} outliers are values < {lb:.2f} or > {ub:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df[num_cols_clean].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def clean_data(df, bounds_dict: dict):\n",
    "    df_clean = deepcopy(df)\n",
    "    print(df_clean.shape)\n",
    "\n",
    "    for k, v in bounds_dict.items():\n",
    "        arr = np.array((df_clean[k] > v[0]) & (df_clean[k] < v[1])).reshape((-1, 1))\n",
    "        print(f\"{k}: bounds: {v}\")\n",
    "        print(f\"  old: {df_clean[k].shape[0]}, new: {np.count_nonzero(arr)}, diff: {np.count_nonzero(arr) - df_clean[k].shape[0]}\")\n",
    "        df_clean = df_clean[(df_clean[k] > v[0]) & (df_clean[k] < v[1])]\n",
    "    return df_clean\n",
    "\n",
    "\n",
    "df_clean = clean_data(df_scaled, bounds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(9, 7.5))\n",
    "sns.boxenplot(data = df_scaled[num_cols_ext], ax = ax[0])\n",
    "ax[0].set_xticks([])\n",
    "ax[0].title.set_text('Before')\n",
    "sns.boxenplot(data = df_clean[num_cols_ext], ax = ax[1])\n",
    "ax[1].title.set_text('After')\n",
    "plt.subplots_adjust(bottom=0.2)\n",
    "plt.xticks(rotation=90)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X = df_clean.drop(['RainTomorrow'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y = df_clean['RainTomorrow']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.7 Обучение и предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_knn = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Разделение выборки на обучающую и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "print(y_train.shape, y_test.shape)\n",
    "model_knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.8 Оценка качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model_knn.predict(X_test)\n",
    "# Ручками\n",
    "print(f\"Test accuracy: {np.mean( y_pred == y_test ):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Методом score\n",
    "model_knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# accuracy_score в sklearn\n",
    "sklearn.metrics.accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Точность модели в зависимости от значения гиперпараметра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "neighbors_settings = range(1, 16)\n",
    "for n_neighbors in neighbors_settings:\n",
    "  clf = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "  clf.fit(X_train, y_train)\n",
    "  training_accuracy.append(clf.score(X_train, y_train))\n",
    "  test_accuracy.append(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "ax.plot(neighbors_settings, training_accuracy, label=\"train accuracy\")\n",
    "ax.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_xlabel(\"Neighbors count\")\n",
    "ax.set_xticks(range(1, 16))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Кросс-валидация (перекрёстная проверка)\n",
    "\n",
    "Перекрестная проверка (кросс-валидация) представляет собой статистический метод оценки обобщающей способности, который является более устойчивым и точным, чем разбиение данных на обучающий и тестовый наборы. В перекрестной проверке данные разбиваются несколько раз и строится несколько моделей. Наиболее часто используемый вариант перекрестной проверки – $k$-блочная кросс-валидация ($k$-fold cross-validation), в которой $k$ – это задаваемое пользователем число, как правило, $5$ или $10$.\n",
    "\n",
    "![crossval-1](https://bitbucket.org/despairr/ds-course-2018/raw/443959e3b5e41168ceba4adcffbe1e9e9084f246/intro-to-ml-images/927.png)\n",
    "\n",
    "В `scikit-learn` перекрестная проверка реализована с помощью функции [sklern.model_selection.cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
    "scores = sklearn.model_selection.cross_val_score(clf, X, y, cv = 3)\n",
    "print(f\"Scores: {scores}\\nAvg score: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors = 3)\n",
    "scores = sklearn.model_selection.cross_val_score(clf, X, y, cv = 5)\n",
    "print(f\"Scores: {scores}\\nAvg score: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "knn_k_list = range(1, 16)\n",
    "cv_k = 10\n",
    "for knn_k in knn_k_list:\n",
    "    clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors = knn_k)\n",
    "    scores = sklearn.model_selection.cross_val_score(clf, X, y, cv = cv_k)\n",
    "    print(f\"Neighbors: {knn_k}, folds count: {cv_k} avg score: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Стратифицированная $k$-блочная кросс-валидация\n",
    "\n",
    "![crossval-2](https://bitbucket.org/despairr/ds-course-2018/raw/443959e3b5e41168ceba4adcffbe1e9e9084f246/intro-to-ml-images/957.png)\n",
    "\n",
    "В стратифицированной перекрестной проверке мы разбиваем данные таким образом, чтобы пропорции классов в каждом блоке в точности соответствовали пропорциям классов в наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "knn_k_list = range(1, 16)\n",
    "cv_k = 10\n",
    "cvgen = sklearn.model_selection.StratifiedKFold(cv_k)\n",
    "for knn_k in knn_k_list:\n",
    "    clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors = knn_k)\n",
    "    scores = sklearn.model_selection.cross_val_score(clf, X, y, cv = cvgen)\n",
    "    print(f\"Neighbors: {knn_k}, stratified folds count: {cv_k} avg score: {scores.mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### 3.9 Метрики оценки точности бинарной классификации\n",
    "\n",
    "В случае бинарной классификации мы говорим о *положительном* (*positive*) классе и *отрицательном* (*negative*) классе, подразумевая под положительным классом интересующий нас класс.\n",
    "\n",
    "*Ошибка первого рода* ($\\alpha$-ошибка, ложноположительное заключение) &ndash; ситуация, когда отвергнута верная нулевая гипотеза (об отсутствии связи между явлениями или искомого эффекта).  \n",
    "*Ошибка второго рода* ($\\beta$-ошибка, ложноотрицательное заключение) &ndash; ситуация, когда принята неверная нулевая гипотеза.  \n",
    "\n",
    "<table style = \"border: 1px solid black;\">\n",
    "    <caption>Confusion matrix</caption>\n",
    "    <tr style = \"border: 1px solid black;\">\n",
    "        <th rowspan=2 colspan=2 style = \"border: 1px solid black;\"></th>\n",
    "        <th colspan=2 style = \"border: 1px solid black;\">Верная гипотеза</th>\n",
    "    </tr>\n",
    "    <tr style = \"border: 1px solid black; background-color: rgba(255, 255, 255, 0.5);\">\n",
    "        <th style = \"border: 1px solid black;\">H<sub>0</sub></th>\n",
    "        <th style = \"border: 1px solid black;\">H<sub>1</sub></th>\n",
    "    </tr>\n",
    "    <tr style = \"border: 1px solid black;\">\n",
    "        <th rowspan=2 style = \"border: 1px solid black;  background-color: rgba(255, 255, 255, 0.25);\">Результат применения критерия</th>\n",
    "        <th style = \"border: 1px solid black;\">H<sub>0</sub></th>\n",
    "        <td style = \"border: 1px solid black; background-color: rgba(0, 255, 0, 0.25); text-align: center;\"><b>H<sub>0</sub></b> верно принята</td>\n",
    "        <td style = \"border: 1px solid black; background-color: rgba(255, 0, 0, 0.25); text-align: center;\"><b>H<sub>0</sub></b> неверно принята<br>(ошибка второго рода)</td>\n",
    "    </tr>\n",
    "    <tr style = \"border: 1px solid black;\">\n",
    "        <th style = \"border: 1px solid black; background-color: rgb(255, 255, 255);\">H<sub>1</sub></th>\n",
    "        <td style = \"border: 1px solid black; background-color: rgba(255, 0, 0, 0.25); text-align: center;\"><b>H<sub>0</sub></b> неверно отвергнута<br>(ошибка первого рода)</td>\n",
    "        <td style = \"border: 1px solid black; background-color: rgba(0, 255, 0, 0.25); text-align: center;\"><b>H<sub>0</sub></b> верно отвергнута</td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style = \"border: 1px solid black; font-size: 42px;\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            TP\n",
    "        </td>\n",
    "        <td>\n",
    "            FN\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            FP\n",
    "        </td>\n",
    "        <td>\n",
    "            TN\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_confusions(y_gt, y_pred):\n",
    "    cm = sklearn.metrics.confusion_matrix(y_gt, y_pred)\n",
    "    # tp fn fp tn\n",
    "    return cm[1, 1], cm[1, 0], cm[0, 1], cm[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors = 15)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "tp, fn, fp, tn = get_confusions(y_test, y_pred)\n",
    "cm = [[tp, fn], [fp, tn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"{cm[0]}\\n{cm[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Accuracy\n",
    "\n",
    "$$\n",
    "Accuracy = \\frac{ TP + TN  }{ TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "Другими словами, правильность &ndash; это количество верно классифицированных примеров ($TP$ и $TN$), поделенное на общее количество примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Ручками\n",
    "def get_accuracy(tp, fn, fp, tn):\n",
    "    return (tp + tn) / (tp + tn + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {get_accuracy(tp, fn, fp, tn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# accuracy_score в sklearn\n",
    "sklearn.metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Точность (precision)\n",
    "\n",
    "$$\n",
    "Precision = \\frac{ TP }{ TP + FP }\n",
    "$$\n",
    "\n",
    "Точность показывает, насколько можно доверять классификатору в случае срабатывания: сколько из предсказанных положительных примеров оказались действительно положительными.\n",
    "\n",
    "Таким образом, точность &ndash; это доля истинно положительных примеров от общего количества предсказанных положительных примеров.\n",
    "\n",
    "Точность используется в качестве показателя качества модели, когда цель состоит в том, чтобы снизить количество ложно положительных примеров.\n",
    "\n",
    "Точность также известна как *прогностическая ценность положительного результата* (*positive predictive value*, *PPV*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_precision(tp, fp):\n",
    "    return tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Precision: {get_precision(tp, fp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# precision_score в sklearn\n",
    "sklearn.metrics.precision_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Полнота (recall)\n",
    "\n",
    "$$\n",
    "Recall = \\frac{ TP }{ TP + FN }\n",
    "$$\n",
    "\n",
    "*Полнота* (*recall*) показывает, на какой доле истинных объектов алгоритм срабатывает.\n",
    "Другие названия *полноты*: *чувствительность* (*sensitivity*), *процент результативных ответов* или *хит-рейт* (*hit rate*) или *доля истинно положительных ответов* (*true positive rate*, *TPR*).\n",
    "\n",
    "Полнота используется в качестве показателя качества модели, когда нам необходимо определить все положительные примеры, то есть, когда важно снизить количество ложно отрицательных примеров.\n",
    "\n",
    "Нужно искать компромисс между оптимизацией полноты и оптимизацией точности. Можно получить идеальную полноту, спрогнозировав все примеры как положительные &ndash; не будет никаких ложно отрицательных и истинно отрицательных примеров. Однако прогнозирование всех примеров как положительных приведет к большому количеству ложно положительных примеров, и, следовательно, точность будет очень низкой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_recall(tp, fn):\n",
    "    return tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Recall: {get_recall(tp, fn)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# recall_score в sklearn\n",
    "sklearn.metrics.recall_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### Интегральные метрики на основе *точности* и *полноты*\n",
    "##### Арифметическое среднее\n",
    "Единая метрика может быть получена как арифметическое среднее точности и полноты:\n",
    "$$\n",
    "A = \\frac{1}{2} \\cdot (precision + recall)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    clf, X_test, y_test, name=\"kNN\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"2-class Precision-Recall curve\")\n",
    "display.ax_.set_aspect('equal', adjustable='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "display = PrecisionRecallDisplay.from_predictions(\n",
    "    y_test, y_pred, name=\"kNN\"\n",
    ")\n",
    "_ = display.ax_.set_title(\"2-class Precision-Recall curve\")\n",
    "display.ax_.set_aspect('equal', adjustable='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### Минимум (precision, recall)\n",
    "\n",
    "$$\n",
    "M = min(precision, recall)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "##### F-мера (f-measure)\n",
    "\n",
    "Одним из способов подытожить их является *F-мера* (*F-measure*), которая представляет собой гармоническое среднее точности и полноты:\n",
    "\n",
    "$$\n",
    "F = 2 \\cdot \\frac{precision \\cdot recall}{precision + recall}\n",
    "$$\n",
    "\n",
    " Она стремится к нулю, если точность или полнота стремится к нулю.\n",
    "\n",
    "Если необходимо отдать предпочтение точности или полноте, следует использовать расширенную F-меру, в которой есть параметр $\\beta$:\n",
    "\n",
    "$$\n",
    "F = (1 + \\beta^2) \\cdot \\frac{ precision \\cdot recall }{ \\beta^2 \\cdot precision + recall }\n",
    "$$\n",
    "\n",
    "где $\\beta$ принимает значения в диапазоне $0 < \\beta < 1$, если вы хотите отдать приоритет точности, а при $\\beta > 1$ приоритет отдается полноте. При $\\beta = 1$ формула сводится к предыдущей и вы получаете сбалансированную F-меру (также ее называют F1).\n",
    "\n",
    "*f-мера* действительно дает более лучшее представление о качестве модели, чем правильность. Однако, в отличие от *правильности*, ее труднее интерпретировать и объяснить."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### `classification_report`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(sklearn.metrics.classification_report(y_test, y_pred, target_names=[\"No rain tomorrow\", \"Rain tomorrow\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#### ROC-кривая\n",
    "\n",
    "Еще один инструмент, который обычно используется для анализа поведения классификаторов при различных пороговых значениях – это кривая *рабочей характеристики приемника* (*receiver operating characteristics curve*) или кратко *ROC-кривая* (*ROC curve*). Как и *кривая точности-полноты*, *ROC-кривая* позволяет рассмотреть все пороговые значения для данного классификатора, но вместо точности и полноты она показывает *долю ложно положительных примеров* (*false positive rate*, $FPR$) в сравнении с *долей истинно положительных примеров* (*true positive rate*, $TPR$).\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "    TPR = \\frac{ TP }{ TP + FN } \\\\\n",
    "    FPR = \\frac{ FP }{ FP + TN }\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "*Доля истинно положительных примеров* – это просто еще одно название *полноты*, тогда как *доля ложно положительных примеров* – это доля ложно положительных примеров от\n",
    "общего количества отрицательных примеров.\n",
    "\n",
    "ROC-кривая строится строится в осях *False Positive Rate* (ось $X$) и *True Positive Rate* (ось $Y$), аналогично $PR$-кривой: постепенно рассматриваются случаи различных значений порогов и отмечаются точки на графике.\n",
    "\n",
    "![ROC-1](https://bitbucket.org/despairr/ds-course-2018/raw/c3f5df9d66d44fe424b4a4f0c0a0195f0ff9b0f7/intro-to-ml-images/1112.png)\n",
    "\n",
    "![ROC-1](https://bitbucket.org/despairr/ds-course-2018/raw/c3f5df9d66d44fe424b4a4f0c0a0195f0ff9b0f7/intro-to-ml-images/1113.png)\n",
    "\n",
    "Кривая стартует с точки $(0, 0)$ и приходит в точку $(1, 1)$. При этом, если существует идеальный классификатор, кривая должна пройти через точку $(0, 1)$. Чем ближе кривая к этой точке, тем лучше будут оценки, а площадь под кривой будет характеризовать качество оценок принадлежности к первому классу. Такая метрика называется $\\textit{AUC-ROC}$, или площадь под $ROC$-кривой.\n",
    "\n",
    "В случае идеального алгоритма $AUC\\text{-}ROC = 1$, а в случае худшего $AUC\\text{-}ROC = \\frac{1}{2}$. Значение $\\textit{AUC-ROC}$ имеет смысл вероятности того, что если были выбраны случайный положительный и случайный отрицательный объекты выборки, положительный объект получит оценку принадлежности выше, чем отрицательный объект."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
